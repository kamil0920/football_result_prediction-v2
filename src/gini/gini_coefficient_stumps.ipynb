{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "from src.helper import get_split_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_trn, y_trn, X_val, y_val, X_tst, y_tst = get_split_data.split_data_for_training()",
   "id": "8cd1b778bf156e90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calc_gini(df, val_col, label_col, pos_val, split_point, debug=False):\n",
    "    \"\"\"\n",
    "    This function calculates the Gini impurity of a dataset. Gini impurity\n",
    "    is a measure of the probability of a random sample being classified\n",
    "    incorrectly when a feature is used to split the data. The lower the\n",
    "    impurity, the better the split.\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    val_col (str): The column name of the feature used to split the data\n",
    "    label_col (str): The column name of the target variable\n",
    "    pos_val (str or int): The value of the target variable that represents\n",
    "    the positive class\n",
    "    split_point (float): The threshold used to split the data.\n",
    "    debug (bool): optional, when set to True, prints the calculated Gini\n",
    "    impurities and the final weighted average\n",
    "    Returns:\n",
    "    float: The weighted average of Gini impurity for the positive and\n",
    "    negative subsets.\n",
    "    \"\"\"\n",
    "\n",
    "    ge_split = df[val_col] >= split_point\n",
    "    eq_pos = df[label_col] == pos_val\n",
    "    tp = df[ge_split & eq_pos].shape[0]\n",
    "    fp = df[ge_split & ~eq_pos].shape[0]\n",
    "    tn = df[~ge_split & ~eq_pos].shape[0]\n",
    "    fn = df[~ge_split & eq_pos].shape[0]\n",
    "    pos_size = tp + fp\n",
    "    neg_size = tn + fn\n",
    "    total_size = len(df)\n",
    "    if pos_size == 0:\n",
    "        gini_pos = 0\n",
    "    else:\n",
    "       gini_pos = 1 - (tp / pos_size) ** 2 - (fp / pos_size) ** 2\n",
    "    if neg_size == 0:\n",
    "        gini_neg = 0\n",
    "    else:\n",
    "        gini_neg = 1 - (tn / neg_size) ** 2 - (fn / neg_size) ** 2\n",
    "    weighted_avg = gini_pos * (pos_size / total_size) + \\\n",
    "                   gini_neg * (neg_size / total_size)\n",
    "    if debug:\n",
    "        print(f'{gini_pos=:.3} {gini_neg=:.3} {weighted_avg=:.3}')\n",
    "\n",
    "    return weighted_avg\n"
   ],
   "id": "45e4057fe0e6efa0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "calc_gini(X_trn.assign(result_match=y_trn), val_col='points_difference', label_col='result_match', pos_val=1, split_point=0, debug=True)",
   "id": "c904f860f49965c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "values = np.arange(-70, 90, .1)\n",
    "ginis = []\n",
    "for v in values:\n",
    "        ginis.append(calc_gini(X_trn.assign(result_match=y_trn), val_col='points_difference', label_col='result_match', pos_val=1, split_point=v, debug=False))\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(values, ginis)\n",
    "ax.set_title('Gini Coefficient')\n",
    "ax.set_ylabel('Gini Coefficient')\n",
    "ax.set_xlabel('Split Point')"
   ],
   "id": "cb1b197fc64e47b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "gini_df = pd.DataFrame({'gini': ginis, 'value': values})\n",
    "print(gini_df.query('gini <= gini.min()'))"
   ],
   "id": "e8fe03964f1ac427",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn import tree\n",
    "import dtreeviz\n",
    "\n",
    "stump_dt = tree.DecisionTreeClassifier(max_depth=1)\n",
    "stump_dt.fit(X_trn, y_trn)"
   ],
   "id": "af37a41a4a7e6e20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_names_str = ['home_win' if cls == 1 else 'home_not_win' for cls in stump_dt.classes_]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "features = list(c for c in X_trn.columns)\n",
    "tree.plot_tree(stump_dt, feature_names=features, filled=True, class_names=class_names_str, ax=ax)"
   ],
   "id": "f174ec30127eaaca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "stump_dt.score(X_val, y_val)",
   "id": "572830c61d7ae9e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn import dummy\n",
    "dummy_model = dummy.DummyClassifier()\n",
    "dummy_model.fit(X_trn, y_trn)\n",
    "dummy_model.score(X_val, y_val)"
   ],
   "id": "6006ef56123b91c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import xgboost as xgb\n",
    "kag_stump = xgb.XGBClassifier(n_estimators=1, max_depth=1)\n",
    "kag_stump.fit(X_trn, y_trn)"
   ],
   "id": "ef07102d29559efc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kag_stump = xgb.XGBClassifier(n_estimators=1, max_depth=1)\n",
    "kag_stump.fit(X_trn, y_trn)\n",
    "kag_stump.score(X_val, y_val)"
   ],
   "id": "1a9d19c08ea4c3d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.helper.plot_tree import my_dot_export\n",
    "\n",
    "my_dot_export(kag_stump, num_trees=0, filename='img/stump_xg_kag.dot', title='XGBoost Stump')"
   ],
   "id": "3e4f02838f5308b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "def inv_logit(p: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the inverse logit function of a given value.\n",
    "    The inverse logit function is defined as:\n",
    "    f(p) = exp(p) / (1 + exp(p))\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : float\n",
    "    The input value to the inverse logit function.\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    The output of the inverse logit function.\n",
    "    \"\"\"\n",
    "    return np.exp(p) / (1 + np.exp(p))"
   ],
   "id": "cee51d6d5593e2dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "inv_logit(-0.012807931)",
   "id": "a959f2713d6b13b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "inv_logit(.182794467)",
   "id": "8f7ec7c51f3f0d9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "997be5c9cbb5ca82",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
